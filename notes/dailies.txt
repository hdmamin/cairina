2/1/23 wed
----------
X -settle on project
X -find all old relevant work
    > added 3 relevant files to this dir for now. The fourth (and perhaps most developed) effort is in the ~/nbextension-duckling dir.
~ -decide how to structure dir(s)/repo(s) (Will prob have multiple semi-related outputs, perhaps 1-5.)
    > Tentatively thinking monorepo. Easier to track everything that way.
-pick repo name
    > cairina, from "cairina moschata", one of the biggest, most powerful looking species of duck ("muscovy"). Think (rubber) duck on steroids.
X -add readme img
    > :D
~ -read distill AI-augmented human intelligence post

2/2/23 thurs
------------
X -premortem
X -map out very tentative plan for order to take things on (e.g. debugger -> jupyter magic -> interactive error messages -> nbextension -> reloading stuff -> LLM native programming language)
    > Lets start with debugger, then jupyter magic. The former is pretty far along and the latter should largely build on top of the debugger. We can take stock after that - depending on timing, can take a break or fit in error messages before break or move on to one of the bigger rocks (live reloading stuff or nbextension) if it went surprisingly fast.
X -consider whether notebook extension proj should continue or start over as jupyterlab extension
    -find stats on how commonly used each is?
        > In 2019 jetbrains python dev survey, DS use cases skewed twoards notebook (13% vs 5%; if we normalize to avoid non-jupyter options, that becomes 72% and 28%). By 2020 survey, it was 11% vs 6% (65% and 35% normalized). In 2021, they didn't break down results by DS users, so it's just 3% vs 2% (60% vs 40% normalized). In the "additional but not main IDE" question, it was 25% vs 12% notebooks (68% vs 32% normalized). In kaggle 2022 survey, 66.5% used nb while 23.7% used lab (74% vs 26% normalized). So (somewhat surprisingly) it seems like notebook is still considerably more popular, though perhaps slowly shifting towards lab. I like nb and started building in that so it's tempting to continue in that, but I guess I don't need to decide quite yet given that we're starting with the debugger.
~ -create cookiecutter template for each major project
    > Just start with debugger subdir (now "roboduck", i.e. a more powerful rubber duck). Uploaded to pypi to claim name.
-finish distill AI-augmented human intelligence post

2/3/23 fri
----------
X -remind myself where I left off w/ debugger work
    X -run existing code (do)
    -skim over existing code (read)
    X -read through done and outstanding todos
    X -write some todo items for what comes next
X -possible bug: seems like if we haven't saved nb since latest changes, load_ipynb func can load an outdated version (possibly? Though tit did that once but then I looked again and it seemed to be up to date so idk)
    > Confirmed that was happening but fixed it w/ help of a stackoverflow function.
X -consider adding option for "I don't know". Or maybe something like "If you don't know what's causing the bug, say "I don't know". Then write a list of 5 plausible causes that the developer can check for when debugging." (take advantage of its strength at generating lists, thinking of possibilities we might not)
X -update prompt to explain to gpt what the chat_db()/roboduck()/rbd() func call is
X -rename usages from llmdb to rdb or similar?
X -update func names to fit roboduck lib
X -add stop word to prompt to prevent starting another question
-finish distill AI-augmented human intelligence post

2/4/23 sat
----------
-see if we can color user/model turns differently. (Bit hard to read atm, though partly bc I'm printing out full prompt for debugging purposes.)
-consider tweaking prompt to use proxy/authority (e.g. "Answer Key")
-hide user warning about using codex model name.

Backlog
-------
-lmdb nb
    -consider if there's a good way to make this more conversational in case we need to ask multiple questions. If we just print gpt's response, this won't work so well. Could try to revise this to fit into ConvManager paradigm.
    -consider how to handle huge data structures (big df, long list, etc.) ~ - See if we can get this to work like ipdb where you can call it only AFTER an error occurs.
    -debug slowness when using magic (is it calling query multiple times?) ~ - add option to add new cell w/ gpt-fixed function below (may need to adjust prompt a bit to encourage it to provide this)
    -consider changing logic for when to call codex (currently when "?" is in text, but should it be more formally defined?)
-watch bret victor Future of Programming vid
-read Engelbart paper on augmenting human intellect

Easy Backlog
------------
-add my jabberwocky pre-commit hook to avoid pushing api key
-add file from jabberwocky (I think?) to avoid counting jupyter notebooks in github code % count
